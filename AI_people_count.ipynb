{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmToDlVh_swg",
        "outputId": "c60388ad-303f-48ad-b168-e9545735a279"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Person 5 exited\n",
            "Person 11 exited\n",
            "Person 22 exited\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "from collections import deque\n",
        "import imageio\n",
        "import time\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Load a pre-trained object detection model and move it to the GPU\n",
        "try:\n",
        "    model = models.detection.fasterrcnn_resnet50_fpn(pretrained=True).to(device)\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model: {e}\")\n",
        "model.eval()\n",
        "\n",
        "# Define a transformation to preprocess the images\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Function to detect people in a frame\n",
        "def detect_people(frame):\n",
        "    image = transform(frame).to(device)  # Move the image tensor to the GPU\n",
        "    image = image.unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image)\n",
        "\n",
        "    scores = outputs[0]['scores'].cpu().numpy()  # Move the outputs back to the CPU\n",
        "    boxes = outputs[0]['boxes'].cpu().numpy()  # Move the outputs back to the CPU\n",
        "    labels = outputs[0]['labels'].cpu().numpy()  # Move the outputs back to the CPU\n",
        "\n",
        "    people_boxes = []\n",
        "    for i, label in enumerate(labels):\n",
        "        if label == 1 and scores[i] > 0.5:  # Label 1 is for 'person' class\n",
        "            people_boxes.append(boxes[i])\n",
        "    return people_boxes\n",
        "\n",
        "# Function to draw bounding boxes and counts\n",
        "def draw_boxes_and_counts(frame, boxes, counts):\n",
        "    for box in boxes:\n",
        "        cv2.rectangle(frame, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), (255, 0, 0), 2)\n",
        "\n",
        "    cv2.putText(frame, f\"Total: {counts['total']}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
        "    cv2.putText(frame, f\"IN: {counts['in']}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "    cv2.putText(frame, f\"OUT: {counts['out']}\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
        "\n",
        "# Function to process the GIF and store the result in a video\n",
        "def process_gif(gif_path, output_path, max_fps=10):\n",
        "    # Initialize counts\n",
        "    counts = {\"total\": 0, \"in\": 0, \"out\": 0}\n",
        "\n",
        "    # Read the GIF\n",
        "    try:\n",
        "        gif = imageio.get_reader(gif_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading GIF: {e}\")\n",
        "        return\n",
        "\n",
        "    # Get GIF properties\n",
        "    meta_data = gif.get_meta_data()\n",
        "    fps = meta_data.get('fps', 10)  # Use 10 FPS as default if 'fps' key is not found\n",
        "    delay = 1 / min(fps, max_fps)\n",
        "    first_frame = gif.get_data(0)\n",
        "    height, width, _ = first_frame.shape\n",
        "    line_y = height // 2\n",
        "\n",
        "    # Initialize video writer\n",
        "    try:\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec\n",
        "        out = cv2.VideoWriter(output_path, fourcc, min(fps, max_fps), (width, height))\n",
        "    except Exception as e:\n",
        "        print(f\"Error initializing video writer: {e}\")\n",
        "        return\n",
        "\n",
        "    # Trackers for people\n",
        "    trackers = []\n",
        "    person_id = 0\n",
        "    person_ids = []\n",
        "    person_states = {}\n",
        "\n",
        "    for frame in gif:\n",
        "        start_time = time.time()\n",
        "\n",
        "        boxes = detect_people(frame)\n",
        "        current_trackers = []\n",
        "        current_ids = []\n",
        "\n",
        "        for box in boxes:\n",
        "            x_center = (box[0] + box[2]) / 2\n",
        "            y_center = (box[1] + box[3]) / 2\n",
        "\n",
        "            # Check if the person is already being tracked\n",
        "            is_new_person = True\n",
        "            for tracker, pid in zip(trackers, person_ids):\n",
        "                if np.linalg.norm(np.array([x_center, y_center]) - np.array(tracker[-1])) < 50:\n",
        "                    tracker.append((x_center, y_center))\n",
        "                    current_trackers.append(tracker)\n",
        "                    current_ids.append(pid)\n",
        "                    is_new_person = False\n",
        "                    break\n",
        "\n",
        "            # If it's a new person, create a new tracker\n",
        "            if is_new_person:\n",
        "                current_trackers.append(deque([(x_center, y_center)], maxlen=50))\n",
        "                current_ids.append(person_id)\n",
        "                person_states[person_id] = \"unknown\"\n",
        "                person_id += 1\n",
        "\n",
        "        # Update trackers\n",
        "        trackers = current_trackers\n",
        "        person_ids = current_ids\n",
        "\n",
        "        # Check for entries and exits\n",
        "        for tracker, pid in zip(trackers, person_ids):\n",
        "            if len(tracker) > 1:\n",
        "                # Check if the person has crossed the line\n",
        "                if tracker[0][1] < line_y and tracker[-1][1] > line_y and person_states[pid] != \"in\":\n",
        "                    counts['in'] += 1\n",
        "                    counts['total'] += 1\n",
        "                    person_states[pid] = \"in\"\n",
        "                    print(f\"Person {pid} entered\")\n",
        "                elif tracker[0][1] > line_y and tracker[-1][1] < line_y and person_states[pid] != \"out\":\n",
        "                    counts['out'] += 1\n",
        "                    counts['total'] -= 1\n",
        "                    person_states[pid] = \"out\"\n",
        "                    print(f\"Person {pid} exited\")\n",
        "\n",
        "        # Draw the line\n",
        "        cv2.line(frame, (0, line_y), (width, line_y), (255, 0, 0), 2)\n",
        "\n",
        "        # Draw boxes and counts on the frame\n",
        "        draw_boxes_and_counts(frame, boxes, counts)\n",
        "\n",
        "        # Write the frame to the output video\n",
        "        out.write(frame)\n",
        "\n",
        "        # Ensure processing respects the FPS limit\n",
        "        elapsed_time = time.time() - start_time\n",
        "        if elapsed_time < delay:\n",
        "            time.sleep(delay - elapsed_time)\n",
        "\n",
        "    out.release()\n",
        "\n",
        "# Process the uploaded GIF and store the result in a video\n",
        "process_gif('/content/Untitled video - Made with Clipchamp.mp4', '/content/output_video.mp4', max_fps=10)\n"
      ]
    }
  ]
}